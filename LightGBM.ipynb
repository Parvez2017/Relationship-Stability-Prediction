{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom sklearn.feature_selection import RFE, RFECV\nfrom sklearn.model_selection import train_test_split, GridSearchCV, KFold\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.ensemble import RandomForestClassifier\n\n\nfrom sklearn import metrics\nfrom sklearn.model_selection import cross_val_predict\nfrom sklearn.metrics import accuracy_score \nfrom sklearn.metrics import f1_score\nfrom imblearn.metrics import geometric_mean_score\nfrom imblearn.metrics import sensitivity_score\nfrom imblearn.metrics import specificity_score\nfrom sklearn.metrics import roc_auc_score\n\nimport lightgbm as lgb","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"df = pd.read_csv(\"../input/promisee/promisin_couples.csv\")\n#df.replace(to_replace = -1 , value =np.nan)\n\nX = df.iloc[:, 0:139].values\ny = df.iloc[:, 139].values\n\n#imputing missing values\nfrom sklearn.impute import KNNImputer\nimputer = KNNImputer()\n#imputer = Imputer(missing_values = 'NaN', strategy = 'most_frequent', axis = 0)\nimputer.fit(X[:, 0:139])\nX[:, 0:139] = imputer.transform(X[:, 0:139])\n\n#Making all the values discrete\nfrom sklearn.preprocessing import KBinsDiscretizer\nest = KBinsDiscretizer(n_bins=5, encode='ordinal', strategy='uniform')\nX = est.fit_transform(X)\n\n# Filter Method: Spearman's Cross Correlation > 0.95\n# Make correlation matrix\ncorr_matrix = pd.DataFrame(X).corr(method = \"spearman\").abs()\n\n# Draw the heatmap\nsns.set(font_scale = 1.0)\nf, ax = plt.subplots(figsize=(11, 9))\nsns.heatmap(corr_matrix, cmap= \"YlGnBu\", square=True, ax = ax)\nf.tight_layout()\nplt.savefig(\"correlation_matrix.png\", dpi = 1080)\n\n# Select upper triangle of matrix\nupper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k = 1).astype(np.bool))\n\n# Find index of feature columns with correlation greater than 0.95\nto_drop = [column for column in upper.columns if any(upper[column] > 0.95)]\n\n# Drop features\nX =pd.DataFrame(X).drop(to_drop, axis = 1)\n\n###############################################################################\n#                  8. Custom pipeline object to use with RFECV                #\n###############################################################################\n# Select Features using RFECV\nclass PipelineRFE(Pipeline):\n    # Source: https://ramhiser.com/post/2018-03-25-feature-selection-with-scikit-learn-pipeline/\n    def fit(self, X, y=None, **fit_params):\n        super(PipelineRFE, self).fit(X, y, **fit_params)\n        self.feature_importances_ = self.steps[-1][-1].feature_importances_\n        return self\n\nscaler = StandardScaler()\nestimator = RandomForestClassifier(n_estimators= 200,\n                                   class_weight ='balanced',\n                                   max_features = 'auto',\n                                   max_depth = 6,\n                                   min_samples_split = 0.005,\n                                   min_samples_leaf = 0.005,\n                                   criterion = 'entropy',\n                                   n_jobs = -1)\nsteps = [(\"scaler\", scaler), (\"classifier\", estimator)]\npipe = PipelineRFE(steps = steps)\n\n# Initialize RFECV object\nfeature_selector = RFECV(pipe, cv = 5, step = 1, min_features_to_select=10, scoring = \"roc_auc\", verbose = 1)\n\n# Fit RFECV\nX = feature_selector.fit_transform(X, y)\n\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20,\n                                                    random_state = 1000)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nscaler = StandardScaler()\nd_train = lgb.Dataset(X_train, label=y_train)\nparams = {'boosting_type': 'gbdt',\n          'max_depth' : -1,\n          'objective': 'binary',\n          'nthread': 3, # Updated from nthread\n          'num_leaves': 64,\n          'learning_rate': 0.05,\n          'max_bin': 512,\n          'subsample_for_bin': 200,\n          'subsample': 1,\n          'subsample_freq': 1,\n          'colsample_bytree': 0.8,\n          'reg_alpha': 5,\n          'reg_lambda': 10,\n          'min_split_gain': 0.5,\n          'min_child_weight': 1,\n          'min_child_samples': 5,\n          'scale_pos_weight': 1,\n          'num_class' : 1,\n          'metric' : 'binary_error'}\n\nclassifier = lgb.LGBMClassifier(boosting_type= 'gbdt',\n          objective = 'binary',\n          n_jobs = 3, # Updated from 'nthread'\n          silent = True,\n          max_depth = params['max_depth'],\n          max_bin = params['max_bin'],\n          subsample_for_bin = params['subsample_for_bin'],\n          subsample = params['subsample'],\n          subsample_freq = params['subsample_freq'],\n          min_split_gain = params['min_split_gain'],\n          min_child_weight = params['min_child_weight'],\n          min_child_samp les = params['min_child_samples'],\n          scale_pos_weight = params['scale_pos_weight'])\n# Define steps in pipeline\nsteps = [(\"scaler\", scaler), (\"classifier\", classifier)]\n    \n# Initialize Pipeline object \npipeline = Pipeline(steps = steps)\n      \n# Define parameter grid\nparam_grid = {\n    'classifier__learning_rate': [0.005],\n    'classifier__n_estimators': [40],\n    'classifier__num_leaves': [6,16],\n    'classifier__boosting_type' : ['gbdt'],\n    'classifier__objective' : ['binary'],\n    'classifier__random_state' : [501], # Updated from 'seed'\n    'classifier__colsample_bytree' : [0.65, 0.66],\n    'classifier__subsample' : [0.7,0.75],\n    'classifier__reg_alpha' : [1.2],\n    'classifier__reg_lambda' : [1],\n    }\n\nclassifier.get_params().keys()\n    \n# Initialize GridSearch object\ngscv = GridSearchCV(pipeline, param_grid, cv = 10,  n_jobs= -1, verbose = 1, scoring = \"roc_auc\")\n                      \n# Fit gscv\ngscv.fit(X_train, y_train) \nclf = gscv.best_estimator_\n        \ny_pred = clf.predict(X_test)\n    \n    \nprint('Accuracy :       ', accuracy_score(y_test, y_pred))\nprint('ROC :            ', roc_auc_score(y_test, y_pred))\nprint('F-Measure :      ', f1_score(y_test, y_pred, average = 'weighted'))\nprint('Geometric Mean : ', geometric_mean_score(y_test, y_pred, average = 'weighted'))\nprint('Sensitivity :    ', sensitivity_score(y_test, y_pred, average = 'weighted'))\nprint('Specificity :    ', specificity_score(y_test, y_pred, average = 'weighted'))\nprint('Type I Error :   ', (1-geometric_mean_score(y_test, y_pred, average = 'weighted')))\nprint('Type II Error :  ', (1-specificity_score(y_test, y_pred, average = 'weighted')))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"gscv.best_params_\n","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}